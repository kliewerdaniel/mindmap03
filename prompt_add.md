This is the rewritten content for `cline_master_prompt.md`, updated to incorporate the detailed project requirements, architecture, data models, and LLM strategy outlined in `spec.md`.

***

### CLINE\_MASTER\_PROMPT.md
### Mind Map AI — CLIne Master Builder Prompt

--------------------------------------------------------------------------------

#### 1. Project Overview
**Project Name:** Mind Map AI — LLM-powered Personal Knowledge Graph (All Local)
**Purpose:** Build a fully local system designed to **convert notes/journals/markdown into a browsable, queryable, and editable knowledge graph**. The system must ingest text or markdown notes, use a local LLM to extract entities, concepts, relationships, and sentiment, store them, and provide an interactive Next.js frontend for visualization and editing.

**Core Goals:**
*   **Entirely local:** LLM inference, database (SQLite), vector store, and graph processing must all operate on-device and remain local.
*   **Auditable transformations:** Every extraction must store source text and provenance.
*   **Support Semantic Search:** Implement semantic search capability for notes and nodes using local vector embeddings.
*   **Interactive Editing:** Allow users to edit nodes/edges manually and commit changes.
*   Incremental iterative development via CLIne prompts.
*   Maintain comprehensive documentation that guides development and adapts with project changes.
*   Track every step, task, and deliverable in a `checklist.md` for observability and iterative progress.

**Constraints:**
*   The system must be offline-capable where possible.
*   The LLM extraction must utilize a **strict JSON schema** defined in `llm_prompting.md`.



--------------------------------------------------------------------------------

#### 2. Technologies & Architecture
The architecture is defined as an all-local stack.

**Frontend:** Next.js (React), utilizing `react-cytoscapejs` for graph visualization.
**Backend:** FastAPI (Python), serving ingestion, graph management, search, and admin endpoints.
**Graph Processing:** NetworkX, representing the graph in memory.
**Graph Persistence:** NetworkX persisted to `.gpickle` or `GraphML` files on disk.
**Database:** SQLite for raw text, metadata, and provenance (source text/note data).
**LLM:** Local model (Ollama, Llama.cpp, or similar Dockerized local model backend).
**Vector Embeddings:** Local `sentence-transformers` model (e.g., all-MiniLM) or Ollama embedding endpoint.
**Vector DB:** Lightweight local Chroma or Faiss is recommended for storing vectors, keyed by node ID or note ID.

**High-Level Architecture Diagram (Detailed):**
[ Next.js Frontend ] <—> [ FastAPI Backend (Python logic, NetworkX) ] <—> [Local LLM Runtime (Ollama/Llama)]
|– SQLite (raw notes + extracts/provenance)
|– NetworkX Graph (.gpickle / GraphML)
|– Vector DB (local Chroma/Faiss embeddings, indexed by node/note ID)



--------------------------------------------------------------------------------

#### 3. Documentation Framework
All documentation should be generated by CLIne initially and updated incrementally as the project evolves. Documentation must live in `/docs/`.

**Files to generate and required content enhancements:**

*   **`architecture.md`**: Diagrams, system overview, folder structure, and rationale for technology choices (Next.js, FastAPI, NetworkX, SQLite, Local LLM).
*   **`api-spec.md`**: Detailed REST endpoint descriptions, request/response formats. Must define and specify the **Core Endpoints** including `/api/ingest/file`, `/api/ingest/text`, `/api/graph`, `/api/search/semantic`, and the mutation endpoints for nodes/edges.
*   **`database.md`**: SQLite schema, table definitions, and the detailed **NetworkX Graph Model** (Node attributes: `id`, `label`, `type`, `provenance`, `embedding`, `created_at`; Edge attributes: `type`, `weight`, `extraction_id`, `provenance`).
*   **`llm_prompting.md`**: Prompt schemas, including the **Extraction Prompt Pattern** (strict JSON output with examples) and the four primary **Roles for LLM** (Extraction, Normalization, Reasoning/Querying, Rewrite/Summarize).
*   **`cicd_devops.md`**: Local Dev Setup, including environment dependencies (Python 3.10+, Node 18+), setup steps for backend (venv, requirements, SQLite schema), frontend (npm install/dev), and configuration for the local LLM endpoint (e.g., Ollama at `http://localhost:11434`).
*   **`testing.md`**: Unit, integration, and end-to-end testing guidelines, covering tests for NetworkX persistence, SQLite operations, and the **Integration Test** flow (Ingest sample markdown → run extraction → assert nodes/edges count).
*   **`security.md`**: Authentication, API security, and confirmation that the default configuration disables external network calls and that raw notes are stored locally in SQLite.
*   **`design_system.md`**: UI/UX rules, including graph visualization patterns (Node color by type, Node size by centrality, Edge thickness by confidence), and key UX interactions (Double-click for provenance, Inline editing).
*   **`roadmap.md` / `decisions.md` / `changelog.md`**: Standard project tracking documentation.

**Documentation Rules:**
*   Every CLIne prompt must reference `/docs/` files.
*   Changes to the system must be reflected in the corresponding documentation.
*   Documentation must include sample JSON (for LLM output), diagrams, code snippets, and usage instructions.
*   CLIne must create `.md` files even with placeholders for sections not yet implemented.



--------------------------------------------------------------------------------

#### 4. Checklist System (checklist.md)

CLIne must maintain a master checklist that includes **all tasks, deliverables, thresholds, and progress**.

---
### DETAILED CRITICAL CHECKLIST TASKS

The project progress must be tracked against the following phases: 0. Setup & Documentation, 1. Core API & Ingestion, 2. Extraction & Persistence, 3. Frontend & Visualization, and 4. Testing & Validation.

#### Phase 0: Setup & Documentation
| Task ID | Description | Deliverable / Threshold | Source |
| :--- | :--- | :--- | :--- |
| 0.1 | **Local Environment Setup** | Install Python 3.10+ and Node 18+. Create Python backend venv and install dependencies (`requirements.txt`). | |
| 0.2 | **LLM Configuration** | Configure local LLM endpoint in `app/config.py`, specifying the LLM server (e.g., Ollama at `http://localhost:11434`). | |
| 0.3 | **Documentation Initialization** | Generate initial versions of all 11 required documentation files in `/docs/`, including `architecture.md`, `api-spec.md`, and `llm_prompting.md`. | |
| 0.4 | **Database Schema Setup** | Run `app/db/schema.sql` to initialize the SQLite database structure for raw notes, extracts, and metadata. | |
| 0.5 | **Embeddings Setup** | Configure the backend to load the local sentence-transformer model (e.g., all-MiniLM) or configure the Ollama embedding endpoint. | |

#### Phase 1: Core API & Ingestion
| Task ID | Description | Deliverable / Threshold | Source |
| :--- | :--- | :--- | :--- |
| 1.1 | **Ingestion Endpoint (Text)** | Implement `POST /api/ingest/text` to accept content, save it to the SQLite notes table, and initiate the asynchronous processing workflow. | |
| 1.2 | **Ingestion Endpoint (File)** | Implement `POST /api/ingest/file` to handle file uploads (single file or zip of markdown files). | |
| 1.3 | **Graph Retrieval API** | Implement `GET /api/graph` (returns full graph or paginated results) and `GET /api/graph/node/{id}` (returns node details and provenance). | |
| 1.4 | **Graph Export API** | Implement `GET /api/export/graph` to return the NetworkX graph persisted as GraphML, GEXF, or gpickle. | |
| 1.5 | **Semantic Search API** | Implement `POST /api/search/semantic` which accepts a query `{"q": "..."}` and returns ranked nodes/notes based on local vector embeddings. | |
| 1.6 | **Mutation Endpoints** | Implement `POST /api/graph/node` and `POST /api/graph/edge` to allow manual editing and committing changes to the NetworkX graph and updating corresponding SQLite entries. | |

#### Phase 2: Extraction & Persistence
| Task ID | Description | Deliverable / Threshold | Source |
| :--- | :--- | :--- | :--- |
| 2.1 | **LLM Extraction Harness** | Create the minimal extractor component that sends text to the local LLM runtime and strictly enforces the **JSON output schema** defined in `llm_prompting.md`. | |
| 2.2 | **Core Ingestion Workflow** | Implement the full sequence within the backend: LLM extraction, writing extraction results to SQLite, updating/merging nodes/edges in NetworkX, and indexing vectors. | |
| 2.3 | **Node Merging Logic** | Implement the logic to assign unique node IDs (based on normalization) and merge nodes that represent the same entity, ensuring the `provenance` list is updated correctly. | |
| 2.4 | **Graph Persistence** | Implement periodic saving of the NetworkX graph using `nx.write_gpickle` to ensure state persistence across application restarts. | |
| 2.5 | **Provenance Tracking** | Ensure every extracted node stores the full provenance (source text spans, `note_id`). | |

#### Phase 3: Frontend & Visualization
| Task ID | Description | Deliverable / Threshold | Source |
| :--- | :--- | :--- | :--- |
| 3.1 | **Frontend Setup** | Initialize the Next.js application, including the basic required pages: `/graph`, `/note/[id]`, `/search`, and `/settings`. | |
| 3.2 | **GraphCanvas Component** | Create the `GraphCanvas` component using `react-cytoscapejs` that fetches graph data from `GET /api/graph` and implements basic pan/zoom functionality. | |
| 3.3 | **Visualization Cues** | Apply initial visualization rules: Node color by type (`concept`, `person`), Node size by centrality, and Edge thickness by confidence score (weight). | |
| 3.4 | **Node Details Panel** | Implement the `NodeDetailsPanel` component that displays node metadata, lists provenance passages, and provides edit buttons when a node is clicked. | |
| 3.5 | **Provenance Interaction** | Implement the key UX interaction: Double-click a node to open the `NodeDetailsPanel` showing source passages. | |

#### Phase 4: Testing & Validation
| Task ID | Description | Deliverable / Threshold | Source |
| :--- | :--- | :--- | :--- |
| 4.1 | **Unit Test Suite** | Implement Unit Tests for NetworkX loading/persistence and SQLite read/write operations. | |
| 4.2 | **Integration Test 1 (Ingestion)** | **Acceptance Test:** Ingest the provided sample notes folder (`data/notes/`) via `/api/ingest/file`. Assert that the process completes and the resulting NetworkX graph contains non-zero nodes (N) and edges (M). | |
| 4.3 | **Integration Test 2 (Export)** | **Acceptance Test:** Implement and run `GET /api/export/graph`. Confirm the exported GraphML/gpickle file contains at least one node with a populated `provenance` attribute. | |
| 4.4 | **Security Check** | Verify that the default configuration disables external network calls, ensuring the system remains entirely local. | |

This continuation details the essential technical specifications for the Mind Map AI project, focusing on data models, LLM requirements, core endpoints, and visualization specifications, as required by `spec.md`.

--------------------------------------------------------------------------------

#### 5. Data Models & Storage Design

The system utilizes SQLite for raw source text and metadata, and NetworkX for the graph structure. Persistence must use `nx.write_gpickle` or `nx.readwrite.gexf.write_gexf`.

##### 5.1. NetworkX Graph Model

The NetworkX graph must rigidly follow these attribute definitions:

**Node Attributes:**
*   **id:** Unique string (e.g., `node:UUID` or `entity:<normalized_text>`).
*   **label:** The display name.
*   **type:** Categorization (e.g., `concept`, `person`, `place`, `idea`, `event`, `passage`).
*   **provenance:** A list of tuples referencing source data: `(note_id, span_start, span_end)`.
*   **embedding:** (Optional, reference to Vector DB) The vector, though the vector itself is usually stored in the local Vector DB and keyed by node id.
*   **created\_at, updated\_at**.
*   **alias list:** Should be kept on node attributes to aid normalization and merging.

**Edge Attributes:**
*   **type:** Relationship category (e.g., `related_to`, `causes`, `elaborates`, `contradicts`, `similar_to`, `part_of`).
*   **weight:** Confidence score of the extraction.
*   **extraction\_id:** ID referencing the entry in the SQLite extracts table.
*   **provenance:** Source spans.

##### 5.2. Normalization Heuristics
The backend must implement logic to normalize entity names to ensure that different mentions (e.g., "AI," "artificial intelligence") map to a single canonical node. This process should utilize the LLM to propose canonical forms and disambiguation. When merging nodes, the `provenance` list must be correctly updated.

--------------------------------------------------------------------------------

#### 6. LLM Strategy & Extraction Pipeline

The entire LLM strategy must utilize a local model (Ollama, LLaMA, or similar).

##### 6.1. Roles for LLM
The local LLM will serve four primary roles:
1.  **Extraction:** Extracting Entities, Concepts, Relationships (with relation types and confidence), Short summaries, and Sentiment/metadata tags from input text.
2.  **Normalization:** Normalizing entity names (e.g., choosing a canonical label).
3.  **Reasoning / Querying:** Answering user questions by synthesizing information from the graph.
4.  **Rewrite / Summarize:** Generating display-ready summaries for nodes.

##### 6.2. Extraction Prompt Pattern
The extraction process must utilize a **strict JSON schema**. The prompt must include short instructions, examples, and explicitly ask the model to return *only* machine-readable JSON.

##### 6.3. Embeddings
A local `sentence-transformer` model (e.g., all-MiniLM) or an Ollama embedding endpoint must be used to embed each note and node label for semantic search functionality. These vectors must be stored in a lightweight local vector store (Chroma or Faiss).

--------------------------------------------------------------------------------

#### 7. API Design: Core Endpoints

The FastAPI backend must expose the following core endpoints:

| HTTP Method | Endpoint | Description |
| :--- | :--- | :--- |
| `POST` | `/api/ingest/file` | Upload a file or zip of markdown files. |
| `POST` | `/api/ingest/text` | Post a text block for asynchronous processing. |
| `GET` | `/api/graph` | Retrieve the full graph or paginated results for visualization. |
| `GET` | `/api/graph/node/{id}` | Retrieve specific node details and its provenance. |
| `POST` | `/api/graph/node` | Add or edit a specific node (manual user intervention). |
| `POST` | `/api/graph/edge` | Add or edit a specific edge (manual user intervention). |
| `POST` | `/api/search/semantic` | Accepts `{"q": "..."}` and returns ranked nodes/notes based on local vector embeddings. |
| `GET` | `/api/export/graph` | Returns the NetworkX graph in GraphML, GEXF, or gpickle format. |

**Ingestion Workflow Requirement:** Upon successful ingestion via `/api/ingest/text`, the backend must perform the sequence: save note to SQLite, run LLM extraction, write extracts, update/merge nodes/edges in NetworkX, and index embeddings.

--------------------------------------------------------------------------------

#### 8. Frontend & Visualization Requirements

The Next.js frontend must provide an interactive visualization and editing environment.

##### 8.1. Key Components & Pages
Critical pages include `/graph` (Full-screen interactive graph viewer) and `/note/[id]` (Note viewer + provenance). Key components are the **GraphCanvas** (`react-cytoscapejs` wrapper) and the **NodeDetailsPanel**.

##### 8.2. Visualization Cues
The visualization must use cues based on graph data:
*   **Node color:** Determined by node `type` (e.g., `concept`, `person`, `event`).
*   **Node size:** Determined by graph analytics results, specifically **centrality** (degree or eigenvector centrality).
*   **Edge thickness:** Determined by the edge `weight` (confidence score).

##### 8.3. UX Interactions
Key interactions must include:
*   **Double-click on a node:** Opens the **NodeDetailsPanel** showing source passages and LLM extraction provenance.
*   **Inline editing:** Allows users to manually edit nodes/edges, triggering a `PATCH` request to the backend mutation endpoints.

##### 8.4. Performance
For large graphs, the visualization should only render a subgraph around the selected node (e.g., BFS to depth 2) to maintain performance.

--------------------------------------------------------------------------------

#### 9. Testing & Validation (Acceptance Criteria)

Testing must cover persistence, data operations, and extraction correctness.

##### 9.1. Acceptance Tests (Critical Thresholds)
1.  **Ingestion/Extraction:** Successfully ingest the provided sample notes folder (`data/notes/`) and confirm the extraction process successfully produces non-zero nodes (N) and edges (M).
2.  **Provenance Check:** Run `GET /api/export/graph` and confirm the exported GraphML/gpickle file contains at least one node with a full `provenance` attribute.

##### 9.2. Security Precondition
The default configuration must explicitly disable external network calls, ensuring the system remains entirely local and offline-capable.








